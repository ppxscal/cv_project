{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (10.2.0)\n",
      "Requirement already satisfied: numpy in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: opencv-python in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: torchvision in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: tqdm in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (4.66.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow numpy torch opencv-python matplotlib seaborn torchvision tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3201/3201 [01:00<00:00, 52.85it/s]\n",
      "100%|██████████| 2241/2241 [00:42<00:00, 53.22it/s]\n",
      "100%|██████████| 897/897 [00:16<00:00, 53.65it/s]\n",
      "100%|██████████| 65/65 [00:01<00:00, 54.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6404, 128, 128]) torch.Size([6404])\n",
      "Corrupted images: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 155/161 [00:00<00:00, 170.21it/s]/home/ppxscal/miniconda3/envs/mit6300/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 161/161 [00:00<00:00, 164.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.042286263489575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 296.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 1.0475603647348357, Validation Accuracy: 53.734756097560975%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 162.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.9360838706448952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 381.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 0.899555199029969, Validation Accuracy: 57.08841463414634%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 163.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.8841765771001022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 392.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 0.8898717761039734, Validation Accuracy: 58.53658536585366%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 164.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.796242917731682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 395.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 0.7493277584634176, Validation Accuracy: 66.23475609756098%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 167.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.6802735380504442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 410.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 0.6225895838039678, Validation Accuracy: 75.3048780487805%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 165.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.5544711965951861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 398.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Loss: 0.7564518887822221, Validation Accuracy: 63.8719512195122%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 167.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.418086557469753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 392.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Loss: 0.4042680508843282, Validation Accuracy: 83.61280487804878%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 166.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.28489164003859396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 384.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Loss: 0.34969379291756125, Validation Accuracy: 85.59451219512195%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 164.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.22482332392879154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 399.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Loss: 0.31154799938383626, Validation Accuracy: 87.04268292682927%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 167.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.1502990144426408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 396.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 0.16749838984957555, Validation Accuracy: 93.4451219512195%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Define the folders containing the images\n",
    "folders = {\n",
    "    0: \"../data/Dataset/Non_Demented/\",\n",
    "    1: \"../data/Dataset/Very_Mild_Demented/\",\n",
    "    2: \"../data/Dataset/Mild_Demented/\",\n",
    "    3: \"../data/Dataset/Moderate_Demented/\",\n",
    "}\n",
    "\n",
    "# Initialize lists to store the images and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "corrupted = 0\n",
    "\n",
    "# Iterate over the folders and load each image\n",
    "for label, path in folders.items():\n",
    "    for filename in tqdm(os.listdir(path)):\n",
    "        # Load the image\n",
    "        img_path = os.path.join(path, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            img = np.zeros((128,128))\n",
    "            corrupted += 1\n",
    "        img_tensor = torch.from_numpy(img).float() \n",
    "        X.append(img_tensor)\n",
    "        y.append(label)\n",
    "\n",
    "X = torch.stack(X)\n",
    "# Normalize the images\n",
    "X = X / 255.0\n",
    "y = torch.tensor(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Calculate the count of each class\n",
    "class_counts = y.bincount()\n",
    "num_samples = y.size(0)\n",
    "class_weights = 1. / class_counts\n",
    "\n",
    "# Create a list of weights for each sample\n",
    "sample_weights = class_weights[y]\n",
    "\n",
    "# Set up the sampler\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "# Create a dataset and a dataloader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "print(f'Corrupted images: {corrupted}')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)  # Assuming 4 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10  # You can adjust this based on your specific needs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoaders for both training and validation sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Starting the training and validation process\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):  # Use train_loader for training\n",
    "        images = images.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {running_loss / len(train_loader)}')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():  # No gradient updates during validation\n",
    "        for images, labels in tqdm(val_loader):  # Use val_loader for validation\n",
    "            images = images.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            val_accuracy += calculate_accuracy(outputs, labels)\n",
    "    \n",
    "    avg_val_loss = val_running_loss / len(val_loader)\n",
    "    avg_val_accuracy = val_accuracy / len(val_loader)\n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {avg_val_loss}, Validation Accuracy: {avg_val_accuracy}% \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit6300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
